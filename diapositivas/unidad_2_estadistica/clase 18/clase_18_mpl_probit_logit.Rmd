---
title: "Reg. con Y dicotomica"
subtitle: "Unidad 2: Estadística Básica y Aplicada"
author: "Nicolás Sidicaro"
date: "Octubre 2025"
institution: "FCE-UBA"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(margins)
library(sandwich)
library(lmtest)
library(caret)
library(knitr)

# Generar datos de ejemplo
set.seed(123)
n <- 1000
datos <- data.frame(
  ingreso = rnorm(n, 50000, 15000),
  score = rnorm(n, 650, 100),
  edad = rnorm(n, 40, 12)
)
datos$ingreso <- pmax(datos$ingreso, 20000)
datos$score <- pmax(pmin(datos$score, 850), 300)
datos$edad <- pmax(datos$edad, 18)

# Variable dependiente
z <- -8 + 0.00008*datos$ingreso + 0.01*datos$score + 0.02*datos$edad
prob <- 1/(1 + exp(-z))
datos$aprobo <- rbinom(n, 1, prob)
```

---

# Introducción y Motivación

### ¿Qué queremos predecir?

**Variable Y que solo toma valores 0 o 1**

Ejemplos:

- Default crediticio (sí/no)
- Aprobación de crédito (aprobado/rechazado)  
- Compra de producto (compra/no compra)
- Recuperación de paciente (recuperado/no recuperado)
- Participación laboral (trabaja/no trabaja)

**Objetivo**: Modelar la probabilidad de que Y = 1 dado un conjunto de variables X

---

# El Problema con MCO

```{r mco-problema, echo=FALSE, fig.height=4, fig.width=7}
# Gráfico mostrando el problema con MCO
x_ejemplo <- seq(300, 850, length.out = 100)
datos_plot <- datos %>% select(score, aprobo)

ggplot(datos_plot, aes(x = score, y = aprobo)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1.5) +
  geom_hline(yintercept = c(0, 1), linetype = "dashed", color = "darkgreen") +
  labs(title = "Problema: MCO predice probabilidades imposibles",
       x = "Score Crediticio", 
       y = "Aprobación (0/1)",
       caption = "La línea roja muestra predicciones fuera de [0,1]") +
  theme_minimal(base_size = 14)
```

**No podemos tener 120% de probabilidad de aprobar un crédito**

---

# Modelo de Probabilidad Lineal (MPL)

## MPL: Idea Básica

**Usar MCO con variable dependiente binaria**

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + u_i$$

donde $Y_i \in \{0, 1\}$

**Interpretación directa y sencilla**:

- $\beta_1$ = cambio en la probabilidad cuando $X_1$ aumenta 1 unidad
- $E[Y_i|X_i] = P(Y_i = 1|X_i) = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i}$

**Ventaja principal**: Coeficientes = efectos marginales

---

# MPL: Ejemplo Práctico

```{r mpl-estimacion}
# Estimar MPL
modelo_mpl <- lm(aprobo ~ ingreso + score + edad, data = datos)
summary(modelo_mpl)$coefficients %>% 
  round(6) %>% 
  kable()
```

**Interpretación**: Por cada punto adicional en el score crediticio, la probabilidad de aprobación aumenta 0.06 puntos porcentuales, manteniendo el resto de las variables constantes

---

# Importante: "Puntos porcentuales" ≠ "Porcentaje"

- Puntos porcentuales: Diferencia absoluta (de 40% a 50% son 10 puntos porcentuales)

- Porcentaje de cambio: Cambio relativo (de 40% a 50% es un aumento del 25%)

En el MPL siempre hablamos de puntos porcentuales (cambio absoluto en la probabilidad).

---

# MPL: Problemas

### 1. Heteroscedasticidad automática

$$Var(u_i|X_i) = P_i(1-P_i)$$

- **Consecuencia**: Errores estándar incorrectos → inferencia inválida
- **Solución**: Errores robustos (White/HC)

### 2. Predicciones imposibles

- Puede predecir $P < 0$ o $P > 1$
- No son probabilidades válidas

```{r mpl-predicciones, echo=FALSE}
pred_mpl <- predict(modelo_mpl)
cat("Predicciones fuera de rango:\n")
cat("P < 0:", sum(pred_mpl < 0), "observaciones\n")
cat("P > 1:", sum(pred_mpl > 1), "observaciones\n")
```

---

# MPL: Solución - Errores Robustos

```{r mpl-robusto}
# MPL con errores robustos
coeftest(modelo_mpl, vcov = vcovHC(modelo_mpl, type = "HC1"))
```

**Nota**: Los coeficientes son iguales, pero los errores estándar cambian

---

# MPL: Variables Dummy

## Interpretación de Variables Dicotómicas

**Variable dummy**: Variable que toma valores 0 o 1 (ej: género, región, tratamiento)

En el MPL, el coeficiente de una dummy tiene una interpretación especial:

$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 D_i + u_i$$

donde $D_i \in \{0, 1\}$

**Interpretación de $\beta_2$**:

- Diferencia en la probabilidad entre tener la característica (D=1) vs no tenerla (D=0)
- **NO** es un cambio incremental, es una **diferencia de grupos**

---

# MPL: Ejemplo con Variable Dummy

```{r mpl-dummy-data, include=FALSE}
# Crear variable dummy para el ejemplo
set.seed(456)
datos$curso_prep <- rbinom(n, 1, 0.4)

# Reestimar modelo con dummy
z_dummy <- -8 + 0.00008*datos$ingreso + 0.01*datos$score + 
           0.02*datos$edad + 0.8*datos$curso_prep
prob_dummy <- 1/(1 + exp(-z_dummy))
datos$aprobo_dummy <- rbinom(n, 1, prob_dummy)
```

```{r mpl-dummy-modelo}
# Estimar MPL con variable dummy
modelo_mpl_dummy <- lm(aprobo_dummy ~ ingreso + score + curso_prep, 
                       data = datos)

summary(modelo_mpl_dummy)$coefficients %>% 
  round(6) %>% 
  kable()
```

**Interpretación del coeficiente de `curso_prep`**:

- Si $\beta_{curso\_prep} = 0.047$ → Las personas que tomaron el curso preparatorio tienen, en promedio, una probabilidad **4,7 puntos porcentuales mayor** de aprobar, manteniendo ingreso y score constantes, respecto a las que no realizaron el curso preparatorio

---

# MPL: Visualización - Variable Dummy

```{r mpl-dummy-plot, echo=FALSE, fig.height=5, fig.width=9}
# Crear datos para predicción
pred_data_dummy <- expand.grid(
  score = seq(min(datos$score), max(datos$score), length.out = 100),
  ingreso = mean(datos$ingreso),
  curso_prep = c(0, 1)
)

# Predicciones
pred_data_dummy$prob_pred <- predict(modelo_mpl_dummy, 
                                     newdata = pred_data_dummy)

# Gráfico
ggplot() +
  geom_point(data = datos, 
             aes(x = score, y = aprobo_dummy, 
                 color = factor(curso_prep, labels = c("Sin curso", "Con curso"))),
             alpha = 0.3, size = 2) +
  geom_line(data = pred_data_dummy,
            aes(x = score, y = prob_pred, 
                color = factor(curso_prep, labels = c("Sin curso", "Con curso")),
                linetype = factor(curso_prep, labels = c("Sin curso", "Con curso"))),
            size = 1.5) +
  scale_color_manual(values = c("Sin curso" = "red", "Con curso" = "blue")) +
  scale_linetype_manual(values = c("Sin curso" = "dashed", "Con curso" = "solid")) +
  labs(title = "MPL: Efecto de Variable Dummy sobre la Probabilidad",
       subtitle = paste("Diferencia vertical = β_curso_prep =", 
                       round(coef(modelo_mpl_dummy)["curso_prep"], 3)),
       x = "Score Crediticio", 
       y = "P(Aprobación = 1)",
       color = "Curso Prep.",
       linetype = "Curso Prep.") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom") +
  annotate("segment", x = 600, xend = 600,
           y = predict(modelo_mpl_dummy, 
                      newdata = data.frame(score = 600, 
                                          ingreso = mean(datos$ingreso),
                                          curso_prep = 0)),
           yend = predict(modelo_mpl_dummy, 
                         newdata = data.frame(score = 600, 
                                             ingreso = mean(datos$ingreso),
                                             curso_prep = 1)),
           arrow = arrow(ends = "both", length = unit(0.2, "cm")),
           color = "darkgreen", size = 1) +
  annotate("text", x = 630, 
           y = mean(c(
             predict(modelo_mpl_dummy, 
                    newdata = data.frame(score = 600, 
                                        ingreso = mean(datos$ingreso),
                                        curso_prep = 0)),
             predict(modelo_mpl_dummy, 
                    newdata = data.frame(score = 600, 
                                        ingreso = mean(datos$ingreso),
                                        curso_prep = 1))
           )),
           label = paste("β =", round(coef(modelo_mpl_dummy)["curso_prep"], 3)),
           color = "darkgreen", size = 5, fontface = "bold")
```

**Nota**: Las líneas son **paralelas** → el efecto de la dummy es **constante** para todos los valores de X

---

# MPL: Interpretación - Dummy vs Continua

## Diferencia Clave en Interpretación

| Tipo de Variable | Interpretación del Coeficiente |
|------------------|-------------------------------|
| **Continua** (ej: score) | Cambio en probabilidad por **cada unidad adicional** |
| **Dummy** (ej: curso_prep) | **Diferencia total** en probabilidad entre grupos |

---

# MPL: Variables Categóricas

## Más de Dos Categorías

**Variable categórica con K categorías** → Se crean K-1 variables dummy

**Ejemplo**: Variable `región` con 3 categorías (Norte, Sur, Oeste)

- Se crea dummy para 2 categorías (ej: `sur` y `oeste`)
- La tercera categoría (`norte`) es la **categoría de referencia**

$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 Sur_i + \beta_3 Oeste_i + u_i$$

**Interpretación**:

- $\beta_2$ = Diferencia en probabilidad entre Sur vs **Norte** (referencia)
- $\beta_3$ = Diferencia en probabilidad entre Oeste vs **Norte** (referencia)

---

# MPL: Ejemplo - Variable Categórica

```{r mpl-categorica-data, include=FALSE}
# Crear variable categórica para el ejemplo
set.seed(789)
datos$region <- sample(c("Norte", "Sur", "Oeste"), n, replace = TRUE, 
                       prob = c(0.4, 0.3, 0.3))

# Efecto de región en probabilidad
efecto_region <- case_when(
  datos$region == "Norte" ~ 0,      # Referencia
  datos$region == "Sur" ~ 0.12,     # +12 pp
  datos$region == "Oeste" ~ -0.08   # -8 pp
)

z_region <- -8 + 0.00008*datos$ingreso + 0.01*datos$score + efecto_region
prob_region <- 1/(1 + exp(-z_region))
datos$aprobo_region <- rbinom(n, 1, prob_region)
```

```{r mpl-categorica-modelo}
# R automáticamente crea las dummies
modelo_mpl_region <- lm(aprobo_region ~ ingreso + score + region, 
                        data = datos)

summary(modelo_mpl_region)$coefficients %>% 
  round(6) %>% 
  kable()
```

---

# MPL: Ejemplo - Variable Categórica

**Interpretación**:

- `regionSur`: Probabilidad de aprobar en el Sur es, en promedio, 3,2 puntos porcentuales **mayor** que en el Norte, ceteris paribus el resto de las variables
- `regionOeste`: Probabilidad de aprobar en el Oeste es, en promedio, 0.2 puntos porcentuales **mayor** que en el Norte

---

# MPL: Visualización - Variable Categórica

```{r mpl-categorica-plot, echo=FALSE, fig.height=5, fig.width=9}
# Crear datos para predicción
pred_data_region <- expand.grid(
  score = seq(min(datos$score), max(datos$score), length.out = 100),
  ingreso = mean(datos$ingreso),
  region = c("Norte", "Sur", "Oeste")
)

# Predicciones
pred_data_region$prob_pred <- predict(modelo_mpl_region, 
                                      newdata = pred_data_region)

# Gráfico
ggplot() +
  geom_point(data = datos, 
             aes(x = score, y = aprobo_region, color = region),
             alpha = 0.3, size = 2) +
  geom_line(data = pred_data_region,
            aes(x = score, y = prob_pred, color = region, linetype = region),
            size = 1.5) +
  scale_color_manual(values = c("Norte" = "darkgreen", 
                                "Sur" = "blue", 
                                "Oeste" = "red")) +
  scale_linetype_manual(values = c("Norte" = "solid", 
                                   "Sur" = "dashed", 
                                   "Oeste" = "dotted")) +
  labs(title = "MPL: Efecto de Variable Categórica sobre la Probabilidad",
       subtitle = "Cada región tiene una línea paralela (intercepto diferente)",
       x = "Score Crediticio", 
       y = "P(Aprobación = 1)",
       color = "Región",
       linetype = "Región") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")
```

**Nota**: Las tres líneas son **paralelas** → diferencias constantes entre regiones

---

# MPL: Comparaciones entre Categorías

## ¿Cómo comparar Sur vs Oeste?

**El modelo solo compara cada categoría vs la referencia**

Para comparar Sur vs Oeste:

**Opción 1**: Cambiar la categoría de referencia

```{r cambiar-referencia}
# Cambiar referencia a "Sur"
datos$region_ref_sur <- relevel(factor(datos$region), ref = "Sur")

modelo_ref_sur <- lm(aprobo_region ~ ingreso + score + region_ref_sur, 
                     data = datos)

# Ahora el coeficiente de "Oeste" compara Oeste vs Sur
coef(modelo_ref_sur)["region_ref_surOeste"] %>% round(4)
```

---

# MPL: Comparaciones entre Categorías (cont.)

**Opción 2**: Test de hipótesis lineal

```{r test-hipotesis, message=FALSE}
library(car)

# H0: β_Sur = β_Oeste (equivalente a β_Sur - β_Oeste = 0)
linearHypothesis(modelo_mpl_region, 
                 "regionSur - regionOeste = 0")
```

**Interpretación**: 

- Rechazamos H0 → Las probabilidades en Sur y Oeste son **significativamente diferentes**
- No rechazamos → No hay evidencia de diferencia entre Sur y Oeste

---

# MPL: Comparaciones entre Categorías (cont.)

En este caso, el p-value del test es de 0.2587, por lo que no rechazamos la hipótesis nula. Es decir, no hay evidencia suficiente para afirmar que haya diferecia entre Sur y Oeste. 

Aunque los coeficientes estimados para Sur y Oeste puedan ser numéricamente distintos, esa diferencia no es estadísticamente significativa. Es decir, la diferencia observada podría deberse simplemente al azar del muestreo.

---

# MPL: Interacciones con Dummies

## ¿Qué pasa si el efecto NO es paralelo?

**Modelo con interacción**: Permite que el efecto de X varíe según la dummy

$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 D_i + \beta_3 (X_i \times D_i) + u_i$$

- $\beta_1$: Efecto de X cuando D=0
- $\beta_1 + \beta_3$: Efecto de X cuando D=1
- $\beta_3$: **Diferencia en el efecto** de X entre grupos

```{r mpl-interaccion}
# Modelo con interacción
modelo_interaccion <- lm(aprobo_dummy ~ score * curso_prep + ingreso, 
                         data = datos)

coef(modelo_interaccion)[c("score", "curso_prep", "score:curso_prep")] %>%
  round(6)
```

---

# MPL: Visualización - Interacción

```{r mpl-interaccion-plot, echo=FALSE, fig.height=5, fig.width=9}
# Predicciones con interacción
pred_interaccion <- expand.grid(
  score = seq(min(datos$score), max(datos$score), length.out = 100),
  ingreso = mean(datos$ingreso),
  curso_prep = c(0, 1)
)

pred_interaccion$prob_pred <- predict(modelo_interaccion, 
                                      newdata = pred_interaccion)

# Comparar modelo con y sin interacción
pred_sin_int <- pred_data_dummy
pred_sin_int$modelo <- "Sin interacción"
pred_con_int <- pred_interaccion
pred_con_int$modelo <- "Con interacción"

pred_combinado <- bind_rows(pred_sin_int, pred_con_int)

ggplot(pred_combinado, 
       aes(x = score, y = prob_pred, 
           color = factor(curso_prep, labels = c("Sin curso", "Con curso")),
           linetype = modelo)) +
  geom_line(size = 1.3) +
  scale_color_manual(values = c("Sin curso" = "red", "Con curso" = "blue")) +
  scale_linetype_manual(values = c("Sin interacción" = "dashed", 
                                   "Con interacción" = "solid")) +
  labs(title = "MPL: Efecto de Interacción",
       subtitle = "Sin interacción = líneas paralelas | Con interacción = pendientes diferentes",
       x = "Score Crediticio", 
       y = "P(Aprobación = 1)",
       color = "Curso Prep.",
       linetype = "Modelo") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")
```

**Interpretación**: Si hay interacción significativa → el efecto del score depende de si tomó el curso

---

# MPL: Resumen - Variables Dummy y Categóricas

**Variables Dummy (0/1)**:

- ✓ Coeficiente = diferencia de probabilidad entre grupos
- ✓ Multiplicar por 100 para puntos porcentuales
- ✓ Líneas paralelas en gráficos

**Variables Categóricas (>2 categorías)**:

- ✓ Se crean K-1 dummies automáticamente
- ✓ Cada coeficiente compara vs categoría de referencia
- ✓ Usar `relevel()` para cambiar referencia
- ✓ Usar `linearHypothesis()` para comparar entre categorías no-referencia

**Interacciones**:

- ✓ Permiten efectos no paralelos
- ✓ Interpretar: "el efecto de X es diferente según D"

---

## MPL: ¿Cuándo Usarlo?

✓ **Aproximación rápida** cuando el tiempo es limitado

✓ **Efectos marginales constantes** son razonables

✓ **Interpretación directa** es prioritaria

✓ **Siempre con errores robustos** para inferencia

✗ Evitar si hay muchas predicciones fuera de [0,1]

✗ No usar si la relación es claramente no lineal

---

# Modelos No Lineales: Logit y Probit

## ¿Por Qué Modelos No Lineales?

**Necesitamos garantizar que** $0 \leq P \leq 1$

**Solución**: Usar una función de distribución que transforme la combinación lineal

$$P(Y_i=1|X_i) = F(\beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i})$$

donde $F(\cdot)$ es una función de distribución acumulada

**Dos opciones principales**:

- **Logit**: $F$ es la distribución logística
- **Probit**: $F$ es la distribución normal estándar

---

# Logit: Función Logística

**Función de distribución logística**:

$$P(Y=1|X) = \frac{e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2}}{1 + e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2}} = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2)}}$$

**Características**:

- Forma de "S" simétrica
- Siempre entre 0 y 1
- Pendiente máxima en P = 0.5
- Permite interpretar odds-ratios

---

# Probit: Distribución Normal

**Función de distribución normal acumulada**:

$$P(Y=1|X) = \Phi(\beta_0 + \beta_1 X_1 + \beta_2 X_2)$$

donde $\Phi$ es la función de distribución normal estándar

**Características**:

- También forma de "S"
- Colas más ligeras que Logit
- Tradición en econometría
- Resultados muy similares a Logit

---

# Comparación Visual

```{r comparacion-modelos, echo=FALSE, fig.height=5, fig.width=8}
# Estimar Logit y Probit
modelo_logit <- glm(aprobo ~ score, data = datos, 
                    family = binomial(link = "logit"))
modelo_probit <- glm(aprobo ~ score, data = datos, 
                     family = binomial(link = "probit"))
modelo_mpl_simple <- lm(aprobo ~ score, data = datos)

# Crear datos para predicción
score_seq <- seq(min(datos$score), max(datos$score), length.out = 200)
pred_data <- data.frame(score = score_seq)

pred_data$mpl <- predict(modelo_mpl_simple, newdata = pred_data)
pred_data$logit <- predict(modelo_logit, newdata = pred_data, type = "response")
pred_data$probit <- predict(modelo_probit, newdata = pred_data, type = "response")

# Gráfico
pred_data %>%
  pivot_longer(cols = c(mpl, logit, probit), names_to = "modelo", values_to = "prob") %>%
  ggplot(aes(x = score, y = prob, color = modelo)) +
  geom_line(linewidth = 1.2) +
  geom_point(data = datos, aes(x = score, y = aprobo), 
             inherit.aes = FALSE, alpha = 0.1, color = "gray50") +
  labs(title = "Comparación: MPL vs Logit vs Probit",
       x = "Score Crediticio", y = "P(Aprobación = 1)",
       color = "Modelo") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")
```

---

# Estimación en R

```{r modelos-estimacion}
# Logit
modelo_logit <- glm(aprobo ~ ingreso + score + edad, 
                    data = datos, 
                    family = binomial(link = "logit"))

# Probit
modelo_probit <- glm(aprobo ~ ingreso + score + edad, 
                     data = datos, 
                     family = binomial(link = "probit"))
```

```{r tabla-comparacion, echo=FALSE}
# Tabla comparativa
tibble(
  Variable = names(coef(modelo_logit)),
  Logit = round(coef(modelo_logit), 4),
  Probit = round(coef(modelo_probit), 4)
) %>% kable()
```

---

# ¿Logit o Probit?

**Logit**:

- ✓ Más común en la práctica
- ✓ Interpretación vía odds-ratios
- ✓ Colas más pesadas (captura eventos extremos)

**Probit**:

- ✓ Tradición econométrica
- ✓ Útil si asumimos normalidad subyacente
- ✓ Ligeramente más fácil en modelos multivariados

**En la práctica**: Los resultados son muy similares. La elección depende más de convención del campo que de consideraciones técnicas.

---

# Interpretación de Resultados

## ⚠️ Problema: Los Coeficientes NO son Efectos Marginales

```{r coef-logit, echo=FALSE}
summary(modelo_logit)$coefficients %>% 
  round(5) %>% 
  kable()
```

**Solo podemos interpretar**:

- ✓ **Signo**: positivo → aumenta P(Y=1); negativo → disminuye P(Y=1)
- ✓ **Significancia**: el coeficiente es estadísticamente distinto de cero

**NO interpretar la magnitud directamente**

---

# Solución 1: Efectos Marginales (RECOMENDADO)

**Efecto marginal**: Cambio en la probabilidad cuando X aumenta en 1 unidad

$$\frac{\partial P(Y=1|X)}{\partial X_j} = f(\beta_0 + \beta_1X_1 + ...) \cdot \beta_j$$

donde $f(\cdot)$ es la función de densidad (derivada de F)

**Dos formas de calcular**:

1. Evaluar en la media de X (at means)
2. Calcular para cada observación y promediar (average marginal effects) ← **Mejor**

---

# Efectos Marginales: Ejemplo

```{r efectos-marginales}
# Calcular efectos marginales promedio
efectos_logit <- margins(modelo_logit)
summary(efectos_logit) %>% 
  select(factor, AME, SE, p) %>%
  kable(digits = 5, col.names = c("Variable", "Efecto Marginal", 
                                   "Error Est.", "p-value"))
```

**Interpretación práctica**:

- Un punto adicional en el score crediticio aumenta la probabilidad de aprobación en **0.06 puntos porcentuales**
---

# Solución 2: Odds-Ratios (Solo Logit)

**Odds (chances)**: $\frac{P(Y=1)}{P(Y=0)}$ = "chances de que ocurra vs no ocurra"

**Odds-Ratio**: $OR = e^{\beta_j}$

```{r odds-ratios}
# Calcular odds-ratios
odds_ratios <- exp(coef(modelo_logit))
tibble(
  Variable = names(odds_ratios),
  `Odds-Ratio` = round(odds_ratios, 4)
) %>% kable()
```

**Interpretación**: Un punto adicional en el score multiplica las chances de aprobación por 1.012

---

# Variables Dicotómicas en Logit/Probit

Una vez que se calculan los efectos marginales promedio en un modelo Probit o Logit, las interpretaciones de las variables categóricas y dummies son las mismas que en el MPL. Se tratan de diferencias de puntos porcentuales entre grupos. 

---

# Código: Efectos Marginales en R

```{r codigo-efectos, eval=FALSE}
# Instalar paquete si no lo tienes
# install.packages("margins")
library(margins)

# Efectos marginales promedio (AME)
efectos <- margins(modelo_logit)
summary(efectos)

# Efectos marginales evaluados en la media (MEM)
efectos_media <- margins(modelo_logit, at = list(
  ingreso = mean(datos$ingreso),
  score = mean(datos$score),
  edad = mean(datos$edad)
))

# Visualizar efectos marginales
plot(efectos)
```

---

# Evaluación de Modelos

## R² de McFadden

**Análogo al R² tradicional para modelos de variable dependiente limitada**

$$R^2_{McFadden} = 1 - \frac{\log L(\hat{\beta})}{\log L(\beta_0)}$$

```{r mcfadden}
# Calcular R² de McFadden
logLik_full <- logLik(modelo_logit)
logLik_null <- logLik(glm(aprobo ~ 1, data = datos, 
                          family = binomial(link = "logit")))

r2_mcfadden <- 1 - (as.numeric(logLik_full) / as.numeric(logLik_null))
cat("R² de McFadden:", round(r2_mcfadden, 4))
```

**Interpretación**: Valores entre 0.2-0.4 son considerados buenos

**Usar R² ajustado** para comparar modelos con diferente número de variables

---

# Matriz de Confusión

**Clasificación**: ¿El modelo predice correctamente?

Necesitamos un **punto de corte** (c): si $\hat{P} > c \rightarrow \hat{Y}=1$

|             | **Predijo Y=0** | **Predijo Y=1** |
|-------------|-----------------|-----------------|
| **Real Y=0** | TN (Verdadero Neg.) ✓ | FP (Falso Pos.) ✗ |
| **Real Y=1** | FN (Falso Neg.) ✗ | TP (Verdadero Pos.) ✓ |

**Métricas**:

- **Tasa de acierto** (Accuracy) = $\frac{TN + TP}{n}$
- **Sensitividad** (Recall) = $\frac{TP}{TP + FN}$ = % de casos positivos bien clasificados
- **Especificidad** = $\frac{TN}{TN + FP}$ = % de casos negativos bien clasificados

---

# Matriz de Confusión: Ejemplo

```{r matriz-confusion}
# Predicciones
predicciones <- predict(modelo_logit, type = "response")

# Clasificación con punto de corte c = 0.5
clase_pred <- ifelse(predicciones > 0.5, 1, 0)

# Matriz de confusión
conf_matrix <- confusionMatrix(
  factor(clase_pred, levels = c(0,1)), 
  factor(datos$aprobo, levels = c(0,1)),
  positive = "1"
)
conf_matrix$table
```

---

# Elección del Punto de Corte

**Diferentes puntos de corte según el objetivo**:

- **c = 0.5**: Estándar, trata FP y FN como igual de costosos
- **c = proporción de Y=1**: Balancea las clases
- **c personalizado**: Depende del costo relativo de errores

**Ejemplo**: En detección de fraude, un falso negativo (fraude no detectado) es más costoso que un falso positivo → usar c más bajo (ej: 0.3)


---

# Supuestos, Problemas y Soluciones

## Supuestos Clave

**1. Independencia de observaciones**

- Las observaciones son independientes entre sí
- Violación común: datos en panel, clustering

**2. Correcta especificación del modelo**

- Forma funcional apropiada
- Variables relevantes incluidas
- No variables irrelevantes que inflen varianza

**3. No multicolinealidad perfecta**

- Las variables independientes no son combinaciones lineales exactas

---

# Problemas Comunes y Soluciones

| Problema | Efecto | Solución |
|----------|--------|----------|
| **Heteroscedasticidad** (MPL) | Errores estándar incorrectos | Errores robustos de White |
| **Predicciones fuera de [0,1]** (MPL) | No interpretable como probabilidad | Usar Logit/Probit |
| **Variables omitidas** | Sesgo en coeficientes | Agregar variables relevantes |
| **Separación perfecta** | Modelo no converge | Penalización (Firth), más datos |
| **Multicolinealidad alta** | Coeficientes inestables | Eliminar variables correlacionadas |

---

## ¡Gracias!

### Preguntas


```{r sessionInfo, echo=FALSE, include=FALSE}
sessionInfo()
```